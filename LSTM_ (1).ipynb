{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aRDBaEieUNFc"
      },
      "source": [
        "## Resource: \n",
        "https://github.com/ekQ/raplysaattori/blob/master/raplyzer.py\n",
        "\n",
        "https://github.com/ekQ/raplysaattori/blob/master/phonetics.py\n",
        "\n",
        "https://mining4meaning.com/2015/02/13/raplyzer/\n",
        "\n",
        "https://towardsdatascience.com/generating-drake-rap-lyrics-using-language-models-and-lstms-8725d71b1b12\n",
        "\n",
        "https://github.com/enriqueav/lstm_lyrics\n",
        "\n",
        "make sentences and create x, y variables https://medium.com/coinmonks/word-level-lstm-text-generator-creating-automatic-song-lyrics-with-neural-networks-b8a1617104fb\n",
        "\n",
        "webscrape: https://www.freecodecamp.org/news/how-to-scrape-websites-with-python-and-beautifulsoup-5946935d93fe/\n",
        "\n",
        "https://stackoverflow.com/questions/42064690/using-pre-trained-word2vec-with-lstm-for-word-generation\n",
        "\n",
        "https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html\n",
        "\n",
        "https://medium.com/@enriqueav/update-automatic-song-lyrics-creator-with-word-embeddings-e30de94db8d1\n",
        "\n",
        "https://towardsdatascience.com/how-to-build-and-deploy-a-lyrics-generation-model-framework-agnostic-589f3026fd53"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kBUTfBF4qjE2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "c4e2ab9c-6fa4-45a1-e143-3c64ccbeb694"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AvJ3RxtnUNFe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "e74e31d9-b846-4b9d-81ea-ffe2b23b72e2"
      },
      "source": [
        "!pip install Unidecode\n",
        "import urllib.request as urllib2\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import re\n",
        "from unidecode import unidecode\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
            "\r\u001b[K     |█▍                              | 10kB 22.5MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20kB 27.3MB/s eta 0:00:01\r\u001b[K     |████▏                           | 30kB 31.5MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 40kB 18.8MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 51kB 13.7MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 61kB 12.5MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 71kB 12.5MB/s eta 0:00:01\r\u001b[K     |███████████                     | 81kB 11.5MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 92kB 11.9MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 102kB 11.9MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 112kB 11.9MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 122kB 11.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 133kB 11.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 143kB 11.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 153kB 11.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 163kB 11.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 174kB 11.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 184kB 11.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 194kB 11.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 204kB 11.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 215kB 11.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 225kB 11.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 235kB 11.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 245kB 11.9MB/s \n",
            "\u001b[?25hInstalling collected packages: Unidecode\n",
            "Successfully installed Unidecode-1.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S_ByVIE_UNFp",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "import random, re\n",
        "import os\n",
        "import io\n",
        "import sys\n",
        "import time\n",
        "##!pip install lyricsgenius\n",
        "#import lyricsgenius\n",
        "#genius = lyricsgenius.Genius(\"DOpXjCEmTPhznrvvwOCmQl5imZKWL2ks1blJeX3EfMasg3Ah-WI083vtSHA7bCoP\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hHEtQN7JUNFt"
      },
      "source": [
        "# Prepare data from picke and use word2vec to generate inputs\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2v_CCPEErR7S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1c6d72e1-e2d9-45cf-a4e2-8093a4cf101e"
      },
      "source": [
        "%cd /content/drive/My Drive/ML/Songs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/ML/Songs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ri0TaOf9UNFu",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "import os\n",
        "import numpy as np\n",
        "import itertools\n",
        "import pandas as pd\n",
        "\n",
        "curDir = r\"/content/drive/My Drive/ML/try_file\"\n",
        "file_name = \"unique_lines_safe.pkl\"\n",
        "os.chdir(curDir)\n",
        "pickle_in = open(file_name,\"rb\")\n",
        "df = pickle.load(pickle_in)\n",
        "\n",
        "verse_line_list= pd.DataFrame(df)\n",
        "\n",
        "verse_line_list.columns =['verse']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7I-x4ezUUNFy",
        "colab": {}
      },
      "source": [
        "import re, string \n",
        "import pandas as pd   \n",
        "from collections import defaultdict\n",
        "import spacy\n",
        "from sklearn.manifold import TSNE\n",
        "from gensim.models import Word2Vec\n",
        "%matplotlib inline\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "g0A_n4NKEC_e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d65ff6ea-ca57-49f9-a66b-ad9d8f5a0dcb"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('stopwords')\n",
        "STOPWORDS = set(stopwords.words('english'))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Tm-9bCSvzKq0",
        "colab": {}
      },
      "source": [
        "\n",
        "def clean_text(text):\n",
        "    '''Make text lowercase, remove text in square brackets, remove punctuation and remove words containing numbers.'''\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\[.*?\\]', '', text)\n",
        "    text = re.sub(r'[%s]' % re.escape(string.punctuation), '', text)\n",
        "    text = re.sub(r'\\w*\\d\\w*', '', text)\n",
        "    return text\n",
        "    # Remove a sentence if it is only one word long\n",
        "    #if len(text) > 2:\n",
        "    #return ' '.join(word for word in text.split() if word not in STOPWORDS)\n",
        "\n",
        "df_clean = pd.DataFrame(verse_line_list.verse.apply(lambda x: clean_text(x)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JlC2zBhGfb4r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ba448ccc-d486-49ca-91ed-8b80043bd82a"
      },
      "source": [
        "df_clean.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(398803, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLw5hi8mkBgX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "e029fe4d-dbaf-4063-b7f1-2bd5d95fd3f5"
      },
      "source": [
        "df_clean = pd.DataFrame(df_clean.verse[0:150000])\n",
        "df_clean.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>verse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>palm angels on my body it protect me from my d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>but im a piranha piranha</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>but when i slip inside i turn girls into slip ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>aint no ifs ands or buts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>and i aint join your team cause i got my own g...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               verse\n",
              "0  palm angels on my body it protect me from my d...\n",
              "1                           but im a piranha piranha\n",
              "2  but when i slip inside i turn girls into slip ...\n",
              "3                           aint no ifs ands or buts\n",
              "4  and i aint join your team cause i got my own g..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPrjYuEiSUZl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "4a4f2693-4370-4b32-c393-9a325b3eaed0"
      },
      "source": [
        "df_clean.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "verse    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Do5aepYvUNF3",
        "colab": {}
      },
      "source": [
        "nlp = spacy.load('en', disable=['ner', 'parser']) # disabling Named Entity Recognition for speed\n",
        "\n",
        "def lemmatizer(verse):        \n",
        "    sent = []\n",
        "    doc = nlp(verse)\n",
        "    for word in doc:\n",
        "        sent.append(word.lemma_)\n",
        "    return \" \".join(sent)\n",
        "\n",
        "df_clean[\"verse_lemmatize\"] =  df_clean.apply(lambda x: lemmatizer(x['verse']), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "02dBQFXmUNF7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "ba344d9a-9055-4590-b930-2c905291eb68"
      },
      "source": [
        "df_clean.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>verse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>palm angels on my body it protect me from my d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>but im a piranha piranha</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>but when i slip inside i turn girls into slip ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>aint no ifs ands or buts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>and i aint join your team cause i got my own g...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               verse\n",
              "0  palm angels on my body it protect me from my d...\n",
              "1                           but im a piranha piranha\n",
              "2  but when i slip inside i turn girls into slip ...\n",
              "3                           aint no ifs ands or buts\n",
              "4  and i aint join your team cause i got my own g..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBWZTEe7esrw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "b4661491-5c7f-4e9c-8146-4b6f8edd2368"
      },
      "source": [
        "length_list = list()\n",
        "for i in range(len(df_clean.verse)):\n",
        "  x = len(df_clean.verse[i].split())\n",
        "  length_list.append(x)\n",
        "df_verse_len_check = pd.concat([df_clean.verse, pd.Series(length_list, name='sentence_length' )], axis=1, sort=False)\n",
        "df_verse_len_check"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>verse</th>\n",
              "      <th>sentence_length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>palm angels on my body it protect me from my d...</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>but im a piranha piranha</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>but when i slip inside i turn girls into slip ...</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>aint no ifs ands or buts</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>and i aint join your team cause i got my own g...</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149995</th>\n",
              "      <td>and all hell i started studying my idols</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149996</th>\n",
              "      <td>so many decisions</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149997</th>\n",
              "      <td>stayin strapped forever trapped in this drug life</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149998</th>\n",
              "      <td>i hope you dont just want me for my lifestyle ...</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149999</th>\n",
              "      <td>size  in girls</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    verse  sentence_length\n",
              "0       palm angels on my body it protect me from my d...               11\n",
              "1                                but im a piranha piranha                5\n",
              "2       but when i slip inside i turn girls into slip ...               12\n",
              "3                                aint no ifs ands or buts                6\n",
              "4       and i aint join your team cause i got my own g...               12\n",
              "...                                                   ...              ...\n",
              "149995           and all hell i started studying my idols                8\n",
              "149996                                  so many decisions                3\n",
              "149997  stayin strapped forever trapped in this drug life                8\n",
              "149998  i hope you dont just want me for my lifestyle ...               12\n",
              "149999                                     size  in girls                3\n",
              "\n",
              "[150000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6flMGZVhei-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "5181d133-15b3-4f50-f2ef-8a718ccc9569"
      },
      "source": [
        "top20_len = df_verse_len_check.sentence_length.sort_values(ascending=False)[0:20]\n",
        "top20_len\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38492     16\n",
              "101563    16\n",
              "113700    15\n",
              "16951     15\n",
              "41853     15\n",
              "99778     15\n",
              "105944    15\n",
              "83177     15\n",
              "146900    15\n",
              "129922    15\n",
              "124804    15\n",
              "7207      15\n",
              "126262    15\n",
              "893       15\n",
              "9145      15\n",
              "28417     15\n",
              "99780     15\n",
              "126256    15\n",
              "49826     15\n",
              "139371    15\n",
              "Name: sentence_length, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jInDBMU7UNGB",
        "colab": {}
      },
      "source": [
        "\n",
        "df_clean['verse_lemmatize_clean'] = df_clean['verse_lemmatize'].str.replace('-PRON-', '')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NUCAoAhQ86S",
        "colab_type": "text"
      },
      "source": [
        "## Plot the top 20 words with most frequency."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DVO5NIolUNGH",
        "colab": {}
      },
      "source": [
        "\n",
        "sentences = [row.split() for row in df_clean['verse']]\n",
        "\n",
        "word_freq = defaultdict(int)\n",
        "for sent in sentences:\n",
        "    for i in sent:\n",
        "        word_freq[i] += 1\n",
        "\n",
        "\n",
        "      \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZ9ZRLYAQs8V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "freq = pd.DataFrame([[k] + [v] for k, v in word_freq.items()], \n",
        "                   columns=['words', 'freq'])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NrGEHuIHUk_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "9d0a5735-10c2-4a99-dec4-b52e5d0264fe"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "pl = freq.sort_values(by=['freq'], ascending=False).iloc[0:20,:]\n",
        "\n",
        "plt.plot(pl.words, pl.freq)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fb725d3b1d0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MuTcrT8moJQN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "9f357806-063c-4123-d31a-065b5320d011"
      },
      "source": [
        "sorted(word_freq, key=word_freq.get, reverse=True)[:20]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the',\n",
              " 'i',\n",
              " 'a',\n",
              " 'you',\n",
              " 'my',\n",
              " 'and',\n",
              " 'to',\n",
              " 'in',\n",
              " 'it',\n",
              " 'me',\n",
              " 'im',\n",
              " 'on',\n",
              " 'like',\n",
              " 'that',\n",
              " 'up',\n",
              " 'with',\n",
              " 'got',\n",
              " 'they',\n",
              " 'of',\n",
              " 'your']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wC4oN1cDoLyn",
        "colab": {}
      },
      "source": [
        "# min_count: minimum number of occurrences of a word in the corpus to be included in the model.\n",
        "# window: the maximum distance between the current and predicted word within a sentence.\n",
        "# size: the dimensionality of the feature vectors\n",
        "# workers: I know my system is having 4 cores, \n",
        "w2v_model = Word2Vec(min_count=1,\n",
        "                     window=5,\n",
        "                     size=300,\n",
        "                     workers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vPIK8SywoZfk",
        "colab": {}
      },
      "source": [
        "w2v_model.build_vocab(sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vIFrlkGaod7K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "d4d686d4-2f6a-4b0d-cb5c-d6260f4a8c77"
      },
      "source": [
        "# train word vectors\n",
        "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=w2v_model.iter)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4729821, 6367085)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hz1j8U-sohfI",
        "colab": {}
      },
      "source": [
        "# As we do not plan to train the model any further, \n",
        "# we are calling init_sims(), which will make the model much more memory-efficient\n",
        "w2v_model.init_sims(replace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuzQHdJS_de_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "fb003b65-df2a-4a3f-ecf7-d9c8fda87ba9"
      },
      "source": [
        "pretrained_weights = w2v_model.wv.syn0\n",
        "vocab_size, emdedding_size = pretrained_weights.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTNxs4YdVjm_",
        "colab_type": "text"
      },
      "source": [
        "## Split sentences as train_x and train_y. train_x is the sentence except the last word. train_y is the last word of teh sentence. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wqfy93b8_x6Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def word2idx(word):\n",
        "  return w2v_model.wv.vocab[word].index\n",
        "def idx2word(idx):\n",
        "  return w2v_model.wv.index2word[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnHzHoo9MZtb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "668f0e31-3461-4c06-bb33-d85d7a806f67"
      },
      "source": [
        "## find the max sentence length\n",
        "ll= list()\n",
        "for i, sentence in enumerate(sentences):\n",
        "  x = len(sentences[i])\n",
        "  ll.append(x)\n",
        "max(ll)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qw4OEsEeD6cM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "23005374-b725-4828-e299-bffe1b6aee11"
      },
      "source": [
        "max_sentence_len=16\n",
        "x = np.zeros([len(sentences), max_sentence_len], dtype=np.int32)\n",
        "y = np.zeros([len(sentences)], dtype=np.int32)\n",
        "for i, sentence in enumerate(sentences):\n",
        "  for t, word in enumerate(sentence[:-1]):\n",
        "    x[i, t] = word2idx(word)\n",
        "    y[i] = word2idx(sentence[-1])\n",
        "print('x shape:', x.shape)\n",
        "print('y shape:', y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x shape: (150000, 16)\n",
            "y shape: (150000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBz3BKX2VxQL",
        "colab_type": "text"
      },
      "source": [
        "# Embedding Wordvec2 model in LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkBIhT4c9MaK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "594202ed-46c0-45f8-d09b-d362af16be1d"
      },
      "source": [
        "from keras.callbacks import LambdaCallback\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "embedding_layer = Embedding(input_dim=vocab_size, output_dim=emdedding_size, \n",
        "                    weights=[pretrained_weights])\n",
        "\n",
        "model = Sequential()\n",
        "model.add(embedding_layer)\n",
        "model.add(LSTM(w2v_model.wv.syn0.shape[1]))\n",
        "model.add(Dense(w2v_model.wv.syn0.shape[0]))   \n",
        "\n",
        "model.add(Activation('softmax'))\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0yMhhaeT5JP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "  if temperature <= 0:\n",
        "    return np.argmax(preds)\n",
        "  preds = np.asarray(preds).astype('float64')\n",
        "  preds = np.log(preds) / temperature\n",
        "  exp_preds = np.exp(preds)\n",
        "  preds = exp_preds / np.sum(exp_preds)\n",
        "  probas = np.random.multinomial(1, preds, 1)\n",
        "  return np.argmax(probas)\n",
        "\n",
        "def generate_next(text, num_generated=10):\n",
        "  word_idxs = [word2idx(word) for word in text.lower().split()]\n",
        "  for i in range(num_generated):\n",
        "    prediction = model.predict(x=np.array(word_idxs))[0]\n",
        "    idx = sample(prediction, temperature=0.7)\n",
        "    word_idxs.append(idx)\n",
        "  return ' '.join(idx2word(idx) for idx in word_idxs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-n3smJCeN-2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ebfa6e33-99cc-4838-a20c-82fc9111cd1e"
      },
      "source": [
        "#!pip install h5py\n",
        "early_stopping =EarlyStopping(monitor='loss',mode = \"min\",  verbose = 1, patience=7)\n",
        "filepath = \"Word2vecLSTM_weights.hdf5\"\n",
        "model_checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, mode='min', save_best_only=True, save_weights_only=True)\n",
        "\n",
        "his= model.fit(x, y,\n",
        "          batch_size=128,\n",
        "          epochs=100,\n",
        "          shuffle=True, \n",
        "          callbacks=[early_stopping, model_checkpoint])\n",
        "\n",
        "#LambdaCallback(on_epoch_end=on_epoch_end)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "150000/150000 [==============================] - 68s 450us/step - loss: 8.3670 - accuracy: 0.0282\n",
            "\n",
            "Epoch 00001: loss improved from inf to 8.36700, saving model to Word2vecLSTM_weights.hdf5\n",
            "Epoch 2/100\n",
            "150000/150000 [==============================] - 68s 453us/step - loss: 7.5418 - accuracy: 0.0577\n",
            "\n",
            "Epoch 00002: loss improved from 8.36700 to 7.54182, saving model to Word2vecLSTM_weights.hdf5\n",
            "Epoch 3/100\n",
            "150000/150000 [==============================] - 70s 467us/step - loss: 6.9146 - accuracy: 0.0819\n",
            "\n",
            "Epoch 00003: loss improved from 7.54182 to 6.91460, saving model to Word2vecLSTM_weights.hdf5\n",
            "Epoch 4/100\n",
            "150000/150000 [==============================] - 71s 470us/step - loss: 6.3566 - accuracy: 0.0996\n",
            "\n",
            "Epoch 00004: loss improved from 6.91460 to 6.35659, saving model to Word2vecLSTM_weights.hdf5\n",
            "Epoch 5/100\n",
            "150000/150000 [==============================] - 69s 461us/step - loss: 5.8048 - accuracy: 0.1203\n",
            "\n",
            "Epoch 00005: loss improved from 6.35659 to 5.80481, saving model to Word2vecLSTM_weights.hdf5\n",
            "Epoch 6/100\n",
            "150000/150000 [==============================] - 71s 471us/step - loss: 5.2401 - accuracy: 0.1502\n",
            "\n",
            "Epoch 00006: loss improved from 5.80481 to 5.24007, saving model to Word2vecLSTM_weights.hdf5\n",
            "Epoch 7/100\n",
            "150000/150000 [==============================] - 69s 457us/step - loss: 4.6705 - accuracy: 0.1960\n",
            "\n",
            "Epoch 00007: loss improved from 5.24007 to 4.67051, saving model to Word2vecLSTM_weights.hdf5\n",
            "Epoch 8/100\n",
            "150000/150000 [==============================] - 69s 461us/step - loss: 4.1228 - accuracy: 0.2607\n",
            "\n",
            "Epoch 00008: loss improved from 4.67051 to 4.12281, saving model to Word2vecLSTM_weights.hdf5\n",
            "Epoch 9/100\n",
            "150000/150000 [==============================] - 71s 471us/step - loss: 3.6227 - accuracy: 0.3296\n",
            "\n",
            "Epoch 00009: loss improved from 4.12281 to 3.62270, saving model to Word2vecLSTM_weights.hdf5\n",
            "Epoch 10/100\n",
            "150000/150000 [==============================] - 70s 463us/step - loss: 3.1909 - accuracy: 0.3942\n",
            "\n",
            "Epoch 00010: loss improved from 3.62270 to 3.19094, saving model to Word2vecLSTM_weights.hdf5\n",
            "Epoch 11/100\n",
            "150000/150000 [==============================] - 67s 447us/step - loss: 2.8284 - accuracy: 0.4524\n",
            "\n",
            "Epoch 00011: loss improved from 3.19094 to 2.82840, saving model to Word2vecLSTM_weights.hdf5\n",
            "Epoch 12/100\n",
            "150000/150000 [==============================] - 68s 452us/step - loss: 2.5193 - accuracy: 0.5041\n",
            "\n",
            "Epoch 00012: loss improved from 2.82840 to 2.51925, saving model to Word2vecLSTM_weights.hdf5\n",
            "Epoch 13/100\n",
            "150000/150000 [==============================] - 68s 453us/step - loss: 2.2576 - accuracy: 0.5481\n",
            "\n",
            "Epoch 00013: loss improved from 2.51925 to 2.25759, saving model to Word2vecLSTM_weights.hdf5\n",
            "Epoch 14/100\n",
            "150000/150000 [==============================] - 67s 449us/step - loss: 2.0210 - accuracy: 0.5916\n",
            "\n",
            "Epoch 00014: loss improved from 2.25759 to 2.02096, saving model to Word2vecLSTM_weights.hdf5\n",
            "Epoch 15/100\n",
            "150000/150000 [==============================] - 69s 458us/step - loss: 1.8149 - accuracy: 0.6294\n",
            "\n",
            "Epoch 00015: loss improved from 2.02096 to 1.81486, saving model to Word2vecLSTM_weights.hdf5\n",
            "Epoch 16/100\n",
            "150000/150000 [==============================] - 68s 454us/step - loss: 1.6417 - accuracy: 0.6614\n",
            "\n",
            "Epoch 00016: loss improved from 1.81486 to 1.64170, saving model to Word2vecLSTM_weights.hdf5\n",
            "Epoch 17/100\n",
            "150000/150000 [==============================] - 67s 449us/step - loss: 1.4834 - accuracy: 0.6911\n",
            "\n",
            "Epoch 00017: loss improved from 1.64170 to 1.48342, saving model to Word2vecLSTM_weights.hdf5\n",
            "Epoch 18/100\n",
            "150000/150000 [==============================] - 67s 449us/step - loss: 1.3430 - accuracy: 0.7172\n",
            "\n",
            "Epoch 00018: loss improved from 1.48342 to 1.34299, saving model to Word2vecLSTM_weights.hdf5\n",
            "Epoch 19/100\n",
            "150000/150000 [==============================] - 68s 453us/step - loss: 1.2141 - accuracy: 0.7433\n",
            "\n",
            "Epoch 00019: loss improved from 1.34299 to 1.21412, saving model to Word2vecLSTM_weights.hdf5\n",
            "Epoch 20/100\n",
            "150000/150000 [==============================] - 68s 455us/step - loss: 1.1074 - accuracy: 0.7638\n",
            "\n",
            "Epoch 00020: loss improved from 1.21412 to 1.10739, saving model to Word2vecLSTM_weights.hdf5\n",
            "Epoch 21/100\n",
            "150000/150000 [==============================] - 69s 457us/step - loss: 1.0030 - accuracy: 0.7858\n",
            "\n",
            "Epoch 00021: loss improved from 1.10739 to 1.00303, saving model to Word2vecLSTM_weights.hdf5\n",
            "Epoch 22/100\n",
            "150000/150000 [==============================] - 69s 459us/step - loss: 0.9167 - accuracy: 0.8029\n",
            "\n",
            "Epoch 00022: loss improved from 1.00303 to 0.91668, saving model to Word2vecLSTM_weights.hdf5\n",
            "Epoch 23/100\n",
            "150000/150000 [==============================] - 69s 457us/step - loss: 0.8347 - accuracy: 0.8200\n",
            "\n",
            "Epoch 00023: loss improved from 0.91668 to 0.83467, saving model to Word2vecLSTM_weights.hdf5\n",
            "Epoch 24/100\n",
            "150000/150000 [==============================] - 68s 455us/step - loss: 0.7786 - accuracy: 0.8317\n",
            "\n",
            "Epoch 00024: loss improved from 0.83467 to 0.77862, saving model to Word2vecLSTM_weights.hdf5\n",
            "Epoch 25/100\n",
            "150000/150000 [==============================] - 68s 456us/step - loss: 0.7068 - accuracy: 0.8471\n",
            "\n",
            "Epoch 00025: loss improved from 0.77862 to 0.70680, saving model to Word2vecLSTM_weights.hdf5\n",
            "Epoch 26/100\n",
            "150000/150000 [==============================] - 67s 447us/step - loss: 0.6438 - accuracy: 0.8603\n",
            "\n",
            "Epoch 00026: loss improved from 0.70680 to 0.64377, saving model to Word2vecLSTM_weights.hdf5\n",
            "Epoch 27/100\n",
            "150000/150000 [==============================] - 67s 444us/step - loss: 0.5987 - accuracy: 0.8688\n",
            "\n",
            "Epoch 00027: loss improved from 0.64377 to 0.59865, saving model to Word2vecLSTM_weights.hdf5\n",
            "Epoch 28/100\n",
            "150000/150000 [==============================] - 67s 448us/step - loss: 0.5570 - accuracy: 0.8784\n",
            "\n",
            "Epoch 00028: loss improved from 0.59865 to 0.55699, saving model to Word2vecLSTM_weights.hdf5\n",
            "Epoch 29/100\n",
            "150000/150000 [==============================] - 68s 450us/step - loss: 0.5105 - accuracy: 0.8879\n",
            "\n",
            "Epoch 00029: loss improved from 0.55699 to 0.51048, saving model to Word2vecLSTM_weights.hdf5\n",
            "Epoch 30/100\n",
            "150000/150000 [==============================] - 68s 452us/step - loss: 0.4758 - accuracy: 0.8956\n",
            "\n",
            "Epoch 00030: loss improved from 0.51048 to 0.47575, saving model to Word2vecLSTM_weights.hdf5\n",
            "Epoch 31/100\n",
            "150000/150000 [==============================] - 67s 449us/step - loss: 0.4471 - accuracy: 0.9018\n",
            "\n",
            "Epoch 00031: loss improved from 0.47575 to 0.44714, saving model to Word2vecLSTM_weights.hdf5\n",
            "Epoch 32/100\n",
            "150000/150000 [==============================] - 67s 446us/step - loss: 0.4176 - accuracy: 0.9080\n",
            "\n",
            "Epoch 00032: loss improved from 0.44714 to 0.41757, saving model to Word2vecLSTM_weights.hdf5\n",
            "Epoch 33/100\n",
            "150000/150000 [==============================] - 67s 450us/step - loss: 0.3883 - accuracy: 0.9141\n",
            "\n",
            "Epoch 00033: loss improved from 0.41757 to 0.38825, saving model to Word2vecLSTM_weights.hdf5\n",
            "Epoch 34/100\n",
            "150000/150000 [==============================] - 67s 446us/step - loss: 0.3757 - accuracy: 0.9159\n",
            "\n",
            "Epoch 00034: loss improved from 0.38825 to 0.37570, saving model to Word2vecLSTM_weights.hdf5\n",
            "Epoch 35/100\n",
            "150000/150000 [==============================] - 67s 449us/step - loss: 0.3621 - accuracy: 0.9183\n",
            "\n",
            "Epoch 00035: loss improved from 0.37570 to 0.36214, saving model to Word2vecLSTM_weights.hdf5\n",
            "Epoch 36/100\n",
            "150000/150000 [==============================] - 67s 444us/step - loss: 0.3347 - accuracy: 0.9251\n",
            "\n",
            "Epoch 00036: loss improved from 0.36214 to 0.33472, saving model to Word2vecLSTM_weights.hdf5\n",
            "Epoch 37/100\n",
            "150000/150000 [==============================] - 67s 443us/step - loss: 0.3039 - accuracy: 0.9329\n",
            "\n",
            "Epoch 00037: loss improved from 0.33472 to 0.30386, saving model to Word2vecLSTM_weights.hdf5\n",
            "Epoch 38/100\n",
            "150000/150000 [==============================] - 67s 446us/step - loss: 0.3068 - accuracy: 0.9306\n",
            "\n",
            "Epoch 00038: loss did not improve from 0.30386\n",
            "Epoch 39/100\n",
            "150000/150000 [==============================] - 66s 438us/step - loss: 0.2925 - accuracy: 0.9333\n",
            "\n",
            "Epoch 00039: loss improved from 0.30386 to 0.29247, saving model to Word2vecLSTM_weights.hdf5\n",
            "Epoch 40/100\n",
            "150000/150000 [==============================] - 66s 438us/step - loss: 0.2824 - accuracy: 0.9357\n",
            "\n",
            "Epoch 00040: loss improved from 0.29247 to 0.28243, saving model to Word2vecLSTM_weights.hdf5\n",
            "Epoch 41/100\n",
            "150000/150000 [==============================] - 67s 445us/step - loss: 0.2699 - accuracy: 0.9377\n",
            "\n",
            "Epoch 00041: loss improved from 0.28243 to 0.26991, saving model to Word2vecLSTM_weights.hdf5\n",
            "Epoch 42/100\n",
            "150000/150000 [==============================] - 67s 444us/step - loss: 0.2643 - accuracy: 0.9387\n",
            "\n",
            "Epoch 00042: loss improved from 0.26991 to 0.26428, saving model to Word2vecLSTM_weights.hdf5\n",
            "Epoch 43/100\n",
            "150000/150000 [==============================] - 66s 439us/step - loss: 0.2464 - accuracy: 0.9431\n",
            "\n",
            "Epoch 00043: loss improved from 0.26428 to 0.24636, saving model to Word2vecLSTM_weights.hdf5\n",
            "Epoch 44/100\n",
            "150000/150000 [==============================] - 65s 434us/step - loss: 0.2382 - accuracy: 0.9454\n",
            "\n",
            "Epoch 00044: loss improved from 0.24636 to 0.23821, saving model to Word2vecLSTM_weights.hdf5\n",
            "Epoch 45/100\n",
            "150000/150000 [==============================] - 66s 443us/step - loss: 0.2443 - accuracy: 0.9423\n",
            "\n",
            "Epoch 00045: loss did not improve from 0.23821\n",
            "Epoch 46/100\n",
            "150000/150000 [==============================] - 66s 439us/step - loss: 0.2304 - accuracy: 0.9463\n",
            "\n",
            "Epoch 00046: loss improved from 0.23821 to 0.23041, saving model to Word2vecLSTM_weights.hdf5\n",
            "Epoch 47/100\n",
            "150000/150000 [==============================] - 66s 440us/step - loss: 0.2224 - accuracy: 0.9482\n",
            "\n",
            "Epoch 00047: loss improved from 0.23041 to 0.22238, saving model to Word2vecLSTM_weights.hdf5\n",
            "Epoch 48/100\n",
            "150000/150000 [==============================] - 67s 444us/step - loss: 0.2186 - accuracy: 0.9485\n",
            "\n",
            "Epoch 00048: loss improved from 0.22238 to 0.21862, saving model to Word2vecLSTM_weights.hdf5\n",
            "Epoch 49/100\n",
            "150000/150000 [==============================] - 66s 437us/step - loss: 0.2132 - accuracy: 0.9489\n",
            "\n",
            "Epoch 00049: loss improved from 0.21862 to 0.21315, saving model to Word2vecLSTM_weights.hdf5\n",
            "Epoch 50/100\n",
            "150000/150000 [==============================] - 66s 441us/step - loss: 0.2091 - accuracy: 0.9508\n",
            "\n",
            "Epoch 00050: loss improved from 0.21315 to 0.20913, saving model to Word2vecLSTM_weights.hdf5\n",
            "Epoch 51/100\n",
            "150000/150000 [==============================] - 67s 445us/step - loss: 0.2102 - accuracy: 0.9497\n",
            "\n",
            "Epoch 00051: loss did not improve from 0.20913\n",
            "Epoch 52/100\n",
            "150000/150000 [==============================] - 66s 440us/step - loss: 0.1981 - accuracy: 0.9527\n",
            "\n",
            "Epoch 00052: loss improved from 0.20913 to 0.19810, saving model to Word2vecLSTM_weights.hdf5\n",
            "Epoch 53/100\n",
            "150000/150000 [==============================] - 66s 438us/step - loss: 0.2042 - accuracy: 0.9505\n",
            "\n",
            "Epoch 00053: loss did not improve from 0.19810\n",
            "Epoch 54/100\n",
            "150000/150000 [==============================] - 66s 438us/step - loss: 0.1986 - accuracy: 0.9521\n",
            "\n",
            "Epoch 00054: loss did not improve from 0.19810\n",
            "Epoch 55/100\n",
            "150000/150000 [==============================] - 66s 443us/step - loss: 0.1880 - accuracy: 0.9552\n",
            "\n",
            "Epoch 00055: loss improved from 0.19810 to 0.18804, saving model to Word2vecLSTM_weights.hdf5\n",
            "Epoch 56/100\n",
            "150000/150000 [==============================] - 67s 448us/step - loss: 0.1946 - accuracy: 0.9528\n",
            "\n",
            "Epoch 00056: loss did not improve from 0.18804\n",
            "Epoch 57/100\n",
            "150000/150000 [==============================] - 67s 444us/step - loss: 0.1896 - accuracy: 0.9537\n",
            "\n",
            "Epoch 00057: loss did not improve from 0.18804\n",
            "Epoch 58/100\n",
            "150000/150000 [==============================] - 67s 445us/step - loss: 0.1744 - accuracy: 0.9585\n",
            "\n",
            "Epoch 00058: loss improved from 0.18804 to 0.17444, saving model to Word2vecLSTM_weights.hdf5\n",
            "Epoch 59/100\n",
            "150000/150000 [==============================] - 66s 440us/step - loss: 0.1786 - accuracy: 0.9566\n",
            "\n",
            "Epoch 00059: loss did not improve from 0.17444\n",
            "Epoch 60/100\n",
            "150000/150000 [==============================] - 66s 443us/step - loss: 0.1845 - accuracy: 0.9541\n",
            "\n",
            "Epoch 00060: loss did not improve from 0.17444\n",
            "Epoch 61/100\n",
            "150000/150000 [==============================] - 66s 442us/step - loss: 0.1745 - accuracy: 0.9572\n",
            "\n",
            "Epoch 00061: loss did not improve from 0.17444\n",
            "Epoch 62/100\n",
            "150000/150000 [==============================] - 66s 441us/step - loss: 0.1705 - accuracy: 0.9581\n",
            "\n",
            "Epoch 00062: loss improved from 0.17444 to 0.17046, saving model to Word2vecLSTM_weights.hdf5\n",
            "Epoch 63/100\n",
            "150000/150000 [==============================] - 66s 437us/step - loss: 0.1689 - accuracy: 0.9579\n",
            "\n",
            "Epoch 00063: loss improved from 0.17046 to 0.16892, saving model to Word2vecLSTM_weights.hdf5\n",
            "Epoch 64/100\n",
            "150000/150000 [==============================] - 65s 436us/step - loss: 0.1700 - accuracy: 0.9581\n",
            "\n",
            "Epoch 00064: loss did not improve from 0.16892\n",
            "Epoch 65/100\n",
            "150000/150000 [==============================] - 65s 436us/step - loss: 0.1818 - accuracy: 0.9537\n",
            "\n",
            "Epoch 00065: loss did not improve from 0.16892\n",
            "Epoch 66/100\n",
            "150000/150000 [==============================] - 65s 436us/step - loss: 0.1732 - accuracy: 0.9567\n",
            "\n",
            "Epoch 00066: loss did not improve from 0.16892\n",
            "Epoch 67/100\n",
            "150000/150000 [==============================] - 66s 442us/step - loss: 0.1507 - accuracy: 0.9632\n",
            "\n",
            "Epoch 00067: loss improved from 0.16892 to 0.15067, saving model to Word2vecLSTM_weights.hdf5\n",
            "Epoch 68/100\n",
            "150000/150000 [==============================] - 65s 436us/step - loss: 0.1632 - accuracy: 0.9596\n",
            "\n",
            "Epoch 00068: loss did not improve from 0.15067\n",
            "Epoch 69/100\n",
            "150000/150000 [==============================] - 66s 439us/step - loss: 0.1610 - accuracy: 0.9596\n",
            "\n",
            "Epoch 00069: loss did not improve from 0.15067\n",
            "Epoch 70/100\n",
            "150000/150000 [==============================] - 66s 440us/step - loss: 0.1666 - accuracy: 0.9581\n",
            "\n",
            "Epoch 00070: loss did not improve from 0.15067\n",
            "Epoch 71/100\n",
            "150000/150000 [==============================] - 66s 442us/step - loss: 0.1571 - accuracy: 0.9608\n",
            "\n",
            "Epoch 00071: loss did not improve from 0.15067\n",
            "Epoch 72/100\n",
            "150000/150000 [==============================] - 66s 442us/step - loss: 0.1524 - accuracy: 0.9618\n",
            "\n",
            "Epoch 00072: loss did not improve from 0.15067\n",
            "Epoch 73/100\n",
            "150000/150000 [==============================] - 66s 438us/step - loss: 0.1536 - accuracy: 0.9614\n",
            "\n",
            "Epoch 00073: loss did not improve from 0.15067\n",
            "Epoch 74/100\n",
            "150000/150000 [==============================] - 65s 435us/step - loss: 0.1422 - accuracy: 0.9645\n",
            "\n",
            "Epoch 00074: loss improved from 0.15067 to 0.14220, saving model to Word2vecLSTM_weights.hdf5\n",
            "Epoch 75/100\n",
            "150000/150000 [==============================] - 65s 436us/step - loss: 0.1507 - accuracy: 0.9620\n",
            "\n",
            "Epoch 00075: loss did not improve from 0.14220\n",
            "Epoch 76/100\n",
            "150000/150000 [==============================] - 65s 436us/step - loss: 0.1584 - accuracy: 0.9592\n",
            "\n",
            "Epoch 00076: loss did not improve from 0.14220\n",
            "Epoch 77/100\n",
            "150000/150000 [==============================] - 65s 434us/step - loss: 0.1507 - accuracy: 0.9614\n",
            "\n",
            "Epoch 00077: loss did not improve from 0.14220\n",
            "Epoch 78/100\n",
            "150000/150000 [==============================] - 66s 440us/step - loss: 0.1479 - accuracy: 0.9619\n",
            "\n",
            "Epoch 00078: loss did not improve from 0.14220\n",
            "Epoch 79/100\n",
            "150000/150000 [==============================] - 67s 443us/step - loss: 0.1555 - accuracy: 0.9594\n",
            "\n",
            "Epoch 00079: loss did not improve from 0.14220\n",
            "Epoch 80/100\n",
            "150000/150000 [==============================] - 66s 441us/step - loss: 0.1340 - accuracy: 0.9662\n",
            "\n",
            "Epoch 00080: loss improved from 0.14220 to 0.13401, saving model to Word2vecLSTM_weights.hdf5\n",
            "Epoch 81/100\n",
            "150000/150000 [==============================] - 66s 440us/step - loss: 0.1390 - accuracy: 0.9649\n",
            "\n",
            "Epoch 00081: loss did not improve from 0.13401\n",
            "Epoch 82/100\n",
            "150000/150000 [==============================] - 66s 437us/step - loss: 0.1506 - accuracy: 0.9613\n",
            "\n",
            "Epoch 00082: loss did not improve from 0.13401\n",
            "Epoch 83/100\n",
            "150000/150000 [==============================] - 66s 442us/step - loss: 0.1423 - accuracy: 0.9632\n",
            "\n",
            "Epoch 00083: loss did not improve from 0.13401\n",
            "Epoch 84/100\n",
            "150000/150000 [==============================] - 66s 442us/step - loss: 0.1391 - accuracy: 0.9640\n",
            "\n",
            "Epoch 00084: loss did not improve from 0.13401\n",
            "Epoch 85/100\n",
            "150000/150000 [==============================] - 67s 447us/step - loss: 0.1413 - accuracy: 0.9630\n",
            "\n",
            "Epoch 00085: loss did not improve from 0.13401\n",
            "Epoch 86/100\n",
            "150000/150000 [==============================] - 66s 440us/step - loss: 0.1439 - accuracy: 0.9626\n",
            "\n",
            "Epoch 00086: loss did not improve from 0.13401\n",
            "Epoch 87/100\n",
            "150000/150000 [==============================] - 67s 446us/step - loss: 0.1421 - accuracy: 0.9631\n",
            "\n",
            "Epoch 00087: loss did not improve from 0.13401\n",
            "Epoch 00087: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1qT7quVYtde",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "7c09c578-c42d-49e0-f66b-8af12c6cd229"
      },
      "source": [
        "print(\"Hyperparameters\")\n",
        "print(\"Data size: \", df_clean.shape[0])\n",
        "print(\"Epochs: \",100 )\n",
        "print('Early Stopping', 86)\n",
        "print(\"Batch size: \", 128)\n",
        "\n",
        "print(\"Layers: \", len(model.layers))\n",
        "print(\"Loss: \", his.history[\"loss\"][-1])\n",
        "print(\"Accuracy: \", his.history[\"accuracy\"][-1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hyperparameters\n",
            "Data size:  150000\n",
            "Epochs:  100\n",
            "Early Stopping 86\n",
            "Batch size:  128\n",
            "Layers:  4\n",
            "Loss:  0.14213323646704357\n",
            "Accuracy:  0.96309334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxnLiER3RtC7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "53b70ec4-cd4a-4a8a-adb2-02be550c0260"
      },
      "source": [
        "# save model\n",
        "import json\n",
        "import optparse\n",
        "\n",
        "# serialize model to JSON\n",
        "final_json = model.to_json()\n",
        "with open(\"word2vec_LSTM.json\", \"w\") as json_file:\n",
        "    json_file.write(final_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"word2vec_LSTM_model.h5\")\n",
        "print(\"Saved model to \")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCmBnLApx12g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validate_seed(vocabulary, seed):\n",
        "    \"\"\"Validate that all the words in the seed are part of the vocabulary\"\"\"\n",
        "    print(\"\\nValidating that all the words in the seed are part of the vocabulary: \")\n",
        "    seed_words = seed\n",
        "    valid = True\n",
        "    for w in seed_words:\n",
        "        print(w, end=\"\")\n",
        "        if w in vocabulary:\n",
        "            print(\" ✓ in vocabulary\")\n",
        "        else:\n",
        "            print(\" ✗ NOT in vocabulary\")\n",
        "            valid = False\n",
        "    return valid\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rP9O3kgaukX-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "a7661430-fc6c-4627-dfab-9bbe91b87cc1"
      },
      "source": [
        "#generate lyrics with a seed:\n",
        "seed = ['hi', 'angel', 'sun', 'love', 'girl', 'when', 'boy', 'that', 'sky', 'today', 'why', 'in', 'no']\n",
        "validate_seed(w2v_model.wv.vocab, [w for w in seed])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Validating that all the words in the seed are part of the vocabulary: \n",
            "hi ✓ in vocabulary\n",
            "angel ✓ in vocabulary\n",
            "sun ✓ in vocabulary\n",
            "love ✓ in vocabulary\n",
            "girl ✓ in vocabulary\n",
            "when ✓ in vocabulary\n",
            "boy ✓ in vocabulary\n",
            "that ✓ in vocabulary\n",
            "sky ✓ in vocabulary\n",
            "today ✓ in vocabulary\n",
            "why ✓ in vocabulary\n",
            "in ✓ in vocabulary\n",
            "no ✓ in vocabulary\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCOl-QTu3-Jd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_lyrics(text, num_generated):\n",
        "  word_idxs = [word2idx(word) for word in text.lower().split()]\n",
        "  for i in range(num_generated):\n",
        "    prediction = model.predict(x=word_idxs)[0]\n",
        "    idx = sample(prediction, temperature=0.7)\n",
        "    word_idxs.append(idx)\n",
        "  return ' '.join(idx2word(idx) for idx in word_idxs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAOyyoH4zUzD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "outputId": "e823f661-f248-400f-c708-743749458b6f"
      },
      "source": [
        "from random import randint\n",
        "\n",
        "lyrics = []\n",
        "for i in range(len(seed)): \n",
        "    x=generate_lyrics(seed[i] , randint(5,15))\n",
        "    lyrics.append(x)\n",
        "    lyrics = list(lyrics)\n",
        "lyrics"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hi murked kickback murked murked permanent murked murked murked intimidated intimidated',\n",
              " 'angel to chanel to superman to drop keep everything respect crack order',\n",
              " 'sun ha open knot grin connect open ha cellular ha ha ha devise',\n",
              " 'love life curtains life meeks life curb life lucci life luminati life gangland life jacks',\n",
              " 'girl salad hot truth ooh ruggedness',\n",
              " 'when dine shaq february armor i february hilfiger judas shes pill aliens',\n",
              " 'boy letterman barking trigga ow blasts skates bullish smirk hah perignon',\n",
              " 'that what jack lean what toasters pump mine deal paranoid what',\n",
              " 'sky peek im hook transactions brawl malcolm im im im im im speaker terrace im',\n",
              " 'today yard yard drinking yard files yard yard guilty yard yard files yard yard',\n",
              " 'why by blue recoup damaged late',\n",
              " 'in gun gun gun gun gun gun gun gun gun gun gun',\n",
              " 'no flop secretary icy legitimate glistening damn supportive gunship dope cheap fouls dope twentyone']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qc-3MRklPkpG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "38337fd4-302d-42b9-93a3-0e619595c727"
      },
      "source": [
        "plt.plot(his.history['loss'])\n",
        "plt.xlabel(\"Epoches\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title('Historical Loss Score')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iy0R9zvWQCzd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "f33c614b-787c-42d5-a03f-53969e9ac54e"
      },
      "source": [
        "plt.plot(his.history['accuracy'])\n",
        "plt.xlabel(\"Epoches\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title('Historical Accuracy Score')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPSp6HKT9hxw",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Qtej5OHnUNG1"
      },
      "source": [
        "## Test the rhyme density"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iddKIjfvUNG1",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "d726b24b-cef2-4970-9004-209e4ad08d0a"
      },
      "source": [
        "import codecs\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "!pip install pyphonetics\n",
        "import pyphonetics as ph"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyphonetics\n",
            "  Downloading https://files.pythonhosted.org/packages/bd/dd/a7d0a860efd3d4335d538b4361b8e9af8311f2aba2e8c7e4c7a47d623b6e/pyphonetics-0.5.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: unidecode<2,>=1 in /usr/local/lib/python3.6/dist-packages (from pyphonetics) (1.1.1)\n",
            "Installing collected packages: pyphonetics\n",
            "Successfully installed pyphonetics-0.5.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UYK1hMC4UNG5",
        "colab": {}
      },
      "source": [
        "\n",
        "class ph:\n",
        "\n",
        "    def is_vow(c, language='fi'):\n",
        "        '''\n",
        "        Is the given (lowercase) character a vowel or not.\n",
        "        '''\n",
        "        if language == 'fi': # Finnish\n",
        "            return c in u'aeiouyäöå'\n",
        "\n",
        "        elif len(language) >= 2 and language[:2] == 'en': # English\n",
        "            # In order to increase recall for the rhyme detection, we \n",
        "            # ignore the schwa vowel '@' as it can be rhymed with several\n",
        "            # different vowels. However, in BattleBot we do not ignore it\n",
        "            # in order to get a higher precision.\n",
        "            return c in u'3L5aAeEiI0VuUoO'\n",
        "\n",
        "        else:\n",
        "            raise Exception(\"Unknown language: %s\" % language)\n",
        "\n",
        "    def map_vow(c, language):\n",
        "        '''\n",
        "        Map vowel to a similar sounding vowel (only for English).\n",
        "        '''\n",
        "        # This list is somewhat arbitrary, so some native English speaker \n",
        "        # who knows about phonetics might be able to improve it.\n",
        "        vow_map = {\n",
        "                '0':'o',\n",
        "                'O':'o',\n",
        "                'I':'i',\n",
        "                'E':'e'\n",
        "                }\n",
        "        if len(language) >= 2 and language[:2] == 'en' and c in vow_map:\n",
        "            return vow_map[c]\n",
        "        else:\n",
        "            return c\n",
        "\n",
        "    def is_space(c):\n",
        "        '''\n",
        "        Is the given character a space or newline (other space characters are \n",
        "        cleaned in the preprocessing phase).\n",
        "        '''\n",
        "        return c==' ' or c=='\\n'\n",
        "\n",
        "    def get_phonetic_transcription(text, language='en-us', output_fname=None):\n",
        "        if output_fname is None:\n",
        "            fname2 = u'temp_transcription.txt'\n",
        "        else:\n",
        "            fname2 = output_fname\n",
        "\n",
        "        if output_fname is None or not os.path.exists(fname2):\n",
        "            print (\"Transcribing: %s\" % fname2)\n",
        "            fname = u'temp_lyrics.txt'\n",
        "            f = codecs.open(fname, 'w', 'utf8')\n",
        "            f.write(text)\n",
        "            f.close()\n",
        "\n",
        "            cmd = u'espeak -xq -v%s -f %s > %s' % (language, fname, fname2)\n",
        "            os.system(cmd)\n",
        "\n",
        "        f2 = codecs.open(fname2, 'r', 'utf8')\n",
        "        new_text = f2.read()\n",
        "\n",
        "        # Remove some unwanted stuff from the transcription\n",
        "        new_text = re.sub(\"_:'Ekskl@m,eIS@n_:\", \"\", new_text)\n",
        "        new_text = re.sub(\"'\", \"\", new_text)\n",
        "        new_text = re.sub(\",\", \"\", new_text)\n",
        "        return new_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o4nwrxvMUNG9",
        "colab": {}
      },
      "source": [
        "class Lyrics:\n",
        "    '''\n",
        "    This class is used to store and preprocess rap lyrics and calculate\n",
        "    statistics like average rhyme length out of the lyrics.\n",
        "    '''\n",
        "\n",
        "    def __init__(self, filename=None, print_stats=False, text=None, \n",
        "                 language='fi', lookback=10):\n",
        "        '''\n",
        "        Lyrics can be read from the file (default) or passed directly\n",
        "        to this constructor.\n",
        "        '''\n",
        "        self.text_raw = None\n",
        "        # How many previous words are checked for a rhyme.\n",
        "        self.lookback = lookback\n",
        "        if filename is not None:\n",
        "            self.filename = filename\n",
        "            f = codecs.open(filename, 'r', 'utf8')\n",
        "            self.text_raw = f.read()\n",
        "            f.close()\n",
        "        elif text is not None:\n",
        "            self.text_raw = text\n",
        "            self.filename = 'No filename'\n",
        "        self.language = language\n",
        "\n",
        "        if self.text_raw is not None:\n",
        "            cleaning_ok = self.clean_text(self.text_raw)\n",
        "            self.compute_vowel_representation()\n",
        "            self.avg_rhyme_length, self.longest_rhyme = self.rhyme_stats()\n",
        "\n",
        "            if print_stats:\n",
        "                #self.print_song_stats_compact()\n",
        "                self.print_song_stats()\n",
        "\n",
        "    def clean_text(self, text):\n",
        "        '''\n",
        "        Preprocess text by removing unwanted characters and duplicate rows.\n",
        "        '''\n",
        "        if self.language == 'fi':\n",
        "            self.text = text.lower()\n",
        "            # Replace all but word characters and newlines by spaces\n",
        "            rx = re.compile(u'[^\\wåäö\\n]+')\n",
        "        else: # English\n",
        "            self.text = text\n",
        "            # For English we need to keep apostrophes since they affect the \n",
        "            # pronunciation\n",
        "            rx = re.compile(u\"[^\\wåÅäÄöÖéÉ'’\\.\\?!\\n]+\")\n",
        "\n",
        "        self.text = rx.sub(' ', self.text)\n",
        "        # If there are more than 2 consecutive newlines, remove some of them\n",
        "        # (just to make the cleaned text look prettier)\n",
        "        self.text = re.sub('\\n\\n+', '\\n\\n', self.text)\n",
        "        # Remove duplicate rows\n",
        "        self.lines = self.text.split('\\n')\n",
        "\n",
        "        uniq_lines = set()\n",
        "        new_text = ''\n",
        "        for l in self.lines:\n",
        "            l = l.strip()\n",
        "            if len(l) > 0 and l in uniq_lines:\n",
        "                continue\n",
        "            # Remove lines that are within brackets/parenthesis\n",
        "            if len(l) >= 2 and ((l[0]=='[' and l[-1]==']') or (l[0]=='(' and l[-1]==')')):\n",
        "                continue\n",
        "            uniq_lines.add(l)\n",
        "            if self.language == 'fi':\n",
        "                new_text += l + '\\n'\n",
        "            else: # English\n",
        "                # Add '.' to the end of line since otherwise the lines might be\n",
        "                # too long so that espeak won't transcribe the whole line\n",
        "                new_text += l + '.\\n'\n",
        "\n",
        "        self.text = new_text\n",
        "\n",
        "    def compute_vowel_representation(self):\n",
        "        '''\n",
        "        Compute a representation of the lyrics where only vowels are preserved.\n",
        "        '''\n",
        "        self.vow = [] # Lyrics with all but vowels removed\n",
        "        self.vow_idxs = [] # Indices of the vowels in self.text list\n",
        "        self.word_ends = [] # Indices of the last characters of each word\n",
        "        self.words = [] # List of words in the lyrics\n",
        "        self.line_idxs = []\n",
        "\n",
        "        if len(self.language) >= 2 and self.language[:2] == 'en':\n",
        "            self.text_orig = self.text\n",
        "            self.text = ph.get_phonetic_transcription(self.text, output_fname=self.filename+'.ipa')\n",
        "            self.word_ends_orig = []\n",
        "            self.words_orig = []\n",
        "\n",
        "        prev_space_idx = -1 # Index of the previous space char\n",
        "        line_idx = 0 # Line index of the current character\n",
        "        # Go through the lyrics char by char\n",
        "        for i in range(len(self.text)):\n",
        "            self.line_idxs.append(line_idx)\n",
        "            c = self.text[i]\n",
        "            c = ph.map_vow(c, self.language)\n",
        "            if ph.is_vow(c, self.language):\n",
        "                # Ignore double vowels\n",
        "                # (in English this applies probably only to 'aa' as in 'bath'\n",
        "                # which rhymes with 'trap' that has only 'a')\n",
        "                if i > 0 and self.text[i-1] == c:\n",
        "                    # Index of a double vowel points to the latter occurrence\n",
        "                    self.vow_idxs[-1] = i\n",
        "                    continue\n",
        "                # TODO Diftongs should not be split (i.e. \"price\" should\n",
        "                # not rhyme with \"trap kit\"). This has been fixed in BattleBot\n",
        "                self.vow.append(c)\n",
        "                self.vow_idxs.append(i)\n",
        "            elif ph.is_space(c):\n",
        "                if c in '\\n':\n",
        "                    line_idx += 1\n",
        "                elif c in '.!?' and i < len(self.text)-1 and self.text[i+1] != '\\n':\n",
        "                    line_idx += 1\n",
        "                # If previous char was not a space, we've encountered word end\n",
        "                if len(self.vow) > 0 and not ph.is_space(self.text[i-1]):\n",
        "                    # Put together the new word. Potential consonants in the \n",
        "                    # end are ignored\n",
        "                    new_word = self.text[prev_space_idx+1:self.vow_idxs[-1]+1]\n",
        "                    # Check that the new word contains at least one vowel\n",
        "                    no_vowels = True\n",
        "                    for c2 in new_word:\n",
        "                        if ph.is_vow(c2, self.language):\n",
        "                            no_vowels = False\n",
        "                            break\n",
        "                    if no_vowels:\n",
        "                        prev_space_idx = i\n",
        "                        continue\n",
        "                    self.word_ends.append(len(self.vow)-1)\n",
        "                    self.words.append(new_word)\n",
        "                prev_space_idx = i\n",
        "\n",
        "        if len(self.language) >= 2 and self.language[:2] == 'en':\n",
        "            self.lines_orig = self.text_orig.split('\\n')\n",
        "\n",
        "    def rhyme_length(self, wpos2):\n",
        "        '''\n",
        "        Length of rhyme (in vowels). The latter part of the rhyme ends with \n",
        "        word self.words[wpos2].\n",
        "        Input:\n",
        "            wpos2       Word index of the end of the rhyme.\n",
        "        '''\n",
        "        max_length = 0\n",
        "        max_wpos1 = None\n",
        "        wpos1 = max(0,wpos2-self.lookback)\n",
        "        while wpos1 < wpos2:\n",
        "            rl = self.rhyme_length_fixed(wpos1, wpos2)\n",
        "            if rl > max_length:\n",
        "                max_length = rl\n",
        "                max_wpos1 = wpos1\n",
        "            wpos1 += 1\n",
        "        return max_length, max_wpos1\n",
        "\n",
        "    def rhyme_length_fixed(self, wpos1, wpos2):\n",
        "        '''\n",
        "        Length of rhyme (in vowels). The first part of the rhyme ends with \n",
        "        self.words[wpos1] and the latter part with word self.words[wpos2].\n",
        "        Input:\n",
        "            wpos1       Word index of the last word in the first part of the rhyme.\n",
        "            wpos2       Word index of the end of the rhyme.\n",
        "        '''\n",
        "        if wpos1 < 0: # Don't wrap\n",
        "            return 0\n",
        "        elif self.words[wpos1] == self.words[wpos2]:\n",
        "            return 0\n",
        "        # Indices in the vowel list\n",
        "        p1 = self.word_ends[wpos1]\n",
        "        p2 = self.word_ends[wpos2]\n",
        "        l = 0\n",
        "        while self.vow[p1-l] == self.vow[p2-l]:\n",
        "            # Make sure that exactly same words are not used\n",
        "            if wpos1 > 0 and p1-l <= self.word_ends[wpos1-1] and wpos2 > 0 and p2-l <= self.word_ends[wpos2-1]:\n",
        "                # Get the first and last character indices of the words surrounding the vowels at p1-l and p2-l\n",
        "                prev_s1 = self.vow_idxs[p1-l]\n",
        "                while prev_s1 > 0 and not ph.is_space(self.text[prev_s1-1]):\n",
        "                    prev_s1 -= 1\n",
        "                prev_s2 = self.vow_idxs[p2-l]\n",
        "                while prev_s2 > 0 and not ph.is_space(self.text[prev_s2-1]):\n",
        "                    prev_s2 -= 1\n",
        "                next_s1 = self.vow_idxs[p1-l]\n",
        "                while next_s1 < len(self.text)-1 and not ph.is_space(self.text[next_s1+1]):\n",
        "                    next_s1 += 1\n",
        "                next_s2 = self.vow_idxs[p2-l]\n",
        "                while next_s2 < len(self.text)-1 and not ph.is_space(self.text[next_s2+1]):\n",
        "                    next_s2 += 1\n",
        "                if next_s1-prev_s1 == next_s2-prev_s2 and self.text[prev_s1:next_s1+1] ==  self.text[prev_s2:next_s2+1]:\n",
        "                    break\n",
        "\n",
        "            l += 1\n",
        "            if p1-l < 0 or p2-l <= p1:\n",
        "                break\n",
        "        # Ignore rhymes with length 1\n",
        "        if l == 1:\n",
        "            l = 0\n",
        "        return l\n",
        "\n",
        "    def rhyme_stats(self):\n",
        "        '''\n",
        "        Compute the average rhyme length of the song and the longest rhyme.\n",
        "        Output:\n",
        "            Average rhyme length (float)\n",
        "            Longest rhyme which is a 3-tuple with: \n",
        "                (length, word index of the first part of the rhyme,\n",
        "                         word index of the latter part of the rhyme)\n",
        "        '''\n",
        "        # Rhyme length of each word\n",
        "        rls = []\n",
        "        # Keep track of the longest rhyme\n",
        "        max_rhyme = (0,None,None)\n",
        "        for wpos2 in range(1,len(self.word_ends)):\n",
        "            (rl, wpos1) = self.rhyme_length(wpos2)\n",
        "            rls.append(rl)\n",
        "            if rl > max_rhyme[0]:\n",
        "                max_rhyme = (rl, wpos1, wpos2)\n",
        "        rls = np.array(rls)\n",
        "        # Average rhyme length of the song\n",
        "        if len(rls) > 0:\n",
        "            avg_rl = np.mean(rls)\n",
        "        else:\n",
        "            avg_rl = 0\n",
        "        return avg_rl, max_rhyme\n",
        "\n",
        "    def get_avg_rhyme_length(self):\n",
        "        return self.avg_rhyme_length\n",
        "\n",
        "    def print_song_stats(self):\n",
        "        print ('------------------------------------------')\n",
        "        print (\"%s\\n\" % self.filename)\n",
        "\n",
        "        print (\"Avg rhyme length: %.3f\\n\" % self.avg_rhyme_length)\n",
        "\n",
        "        self.print_rhyme(self.longest_rhyme)\n",
        "        print\n",
        "        #print '------------------------------------------'\n",
        "\n",
        "    def print_song_stats_compact(self):\n",
        "        print (\"%.3f  %s\" % (self.avg_rhyme_length, self.filename))\n",
        "\n",
        "    def print_rhyme(self, rhyme_tuple):\n",
        "        print (self.get_rhyme_str(rhyme_tuple))\n",
        "\n",
        "    def get_rhyme_str(self, rhyme_tuple):\n",
        "        '''\n",
        "        Construct a string of a given rhyme tuple.\n",
        "        '''\n",
        "        ret = ''\n",
        "        rl, wpos1, wpos2 = rhyme_tuple\n",
        "        if wpos1 is None or wpos2 is None:\n",
        "            return ''\n",
        "        p2 = self.vow_idxs[self.word_ends[wpos2]]\n",
        "        p2_orig = p2\n",
        "        # Find the ending of the last word\n",
        "        while not ph.is_space(self.text[p2]):\n",
        "            p2 += 1\n",
        "        p0 = self.vow_idxs[self.word_ends[wpos1]-rl]\n",
        "        p0_orig = p0\n",
        "        # Find the beginning of the line\n",
        "        while self.text[p0] != '\\n' and p0 > 0:\n",
        "            p0 -= 1\n",
        "\n",
        "        cap_line = ''\n",
        "        rw1, rw2 = self.get_rhyming_vowels(rhyme_tuple)\n",
        "        for i in range(p0,p2+1):\n",
        "            if self.language == 'fi':\n",
        "                if i in rw1 or i in rw2:\n",
        "                    cap_line += self.text[i].capitalize()\n",
        "                else:\n",
        "                    cap_line += self.text[i]\n",
        "            else:\n",
        "                if i == min(rw1) or i == min(rw2):\n",
        "                    cap_line += ' | ' + self.text[i]\n",
        "                elif i == max(rw1) or i == max(rw2):\n",
        "                    cap_line += self.text[i] + '|'\n",
        "                else:\n",
        "                    cap_line += self.text[i]\n",
        "        ret += \"Longest rhyme (l=%d): %s\\n\" % (rl, cap_line)\n",
        "        if self.language != 'fi':\n",
        "            # Get the corresponding lines from the original lyrics\n",
        "            line_beg = self.line_idxs[p0]\n",
        "            line_end = self.line_idxs[p2]\n",
        "            for i in range(line_beg, line_end+1):\n",
        "                if i < len(self.lines_orig):\n",
        "                    ret += self.lines_orig[i] + '\\n'\n",
        "        return ret\n",
        "\n",
        "    def get_longest_rhyme(self):\n",
        "        rhyme_str = self.get_rhyme_str(self.longest_rhyme)\n",
        "        rhyme_str += self.filename + '\\n'\n",
        "        return self.longest_rhyme[0], rhyme_str\n",
        "\n",
        "    def get_rhyming_vowels(self, rhyme_tuple):\n",
        "        '''\n",
        "        Return the indices of the rhyming vowels of the longest rhyme.\n",
        "        Output:\n",
        "            Tuple with the indices of the first part and the second part of\n",
        "            the rhyme separately.\n",
        "        '''\n",
        "        rl, wpos1, wpos2 = rhyme_tuple\n",
        "        if wpos1 is None or wpos2 is None:\n",
        "            return ([-1],[-1])\n",
        "\n",
        "        # The first part of the rhyme\n",
        "        rhyme_idxs1 = [] # Indices of the rhyming vowels\n",
        "        n_caps = 0\n",
        "        p = self.vow_idxs[self.word_ends[wpos1]]\n",
        "        while n_caps < rl:\n",
        "            if ph.is_vow(self.text[p], self.language):\n",
        "                rhyme_idxs1.append(p)\n",
        "                # Increase the counter only if the vowel is not a double vowel\n",
        "                if self.text[p] != self.text[p+1]:\n",
        "                    n_caps += 1\n",
        "            p -= 1\n",
        "\n",
        "        # The second part of the rhyme\n",
        "        rhyme_idxs2 = [] # Indices of the rhyming vowels\n",
        "        n_caps = 0\n",
        "        p = self.vow_idxs[self.word_ends[wpos2]]\n",
        "        p_last = p\n",
        "        while n_caps < rl:\n",
        "            if ph.is_vow(self.text[p], self.language):\n",
        "                rhyme_idxs2.append(p)\n",
        "                # Increase the counter only if the vowel is not a double vowel.\n",
        "                # The last vowel must be always counted.\n",
        "                if p == p_last or self.text[p] != self.text[p+1]:\n",
        "                    n_caps += 1\n",
        "            p -= 1\n",
        "\n",
        "        return (rhyme_idxs1, rhyme_idxs2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yP-eyp6XusFi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('lyric.txt', 'w') as file:\n",
        "\n",
        "    for item in lyrics:\n",
        "        file.write('%s\\n' %item)\n",
        "        \n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8t8elMdDLCf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "59ebc2c0-9e3c-4428-ca43-dd0595f9363a"
      },
      "source": [
        "x=Lyrics(\"lyric.txt\")\n",
        "x.get_avg_rhyme_length()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5629139072847682"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    }
  ]
}